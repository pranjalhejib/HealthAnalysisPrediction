{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pandas import read_csv, DataFrame\n","import pandas as pd\n","from pandas.plotting import scatter_matrix\n","from matplotlib import pyplot\n","import seaborn as sns\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","import os\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = None\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Classification:\n","    def __init__(self):\n","        self.names = ['age', 'sex',\n","                      'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n","                      'oldpeak', 'slope', 'ca', 'thal', 'target']\n","        self.path = os.getcwd()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# PATH SETTINGS HERE\n","# self.path=self.path+\"\\\\data\\\\heart.csv\"             #uncomment this if running Classification.py\n","# uncomment this if running djnago server\n","self.path = self.path + \"/bsapp/data/heart.csv\"\n","print(self.path)\n","self.ds = pd.read_csv(self.path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# self.path = os.getcwd() + \"\\\\data\\\\heart.csv\"                   #uncomment this if running Classification.py\n","# uncomment this if running djnago server\n","self.path = os.getcwd() + \"\\\\bsapp\\\\data\\\\heart.csv\"\n","self.dsl = pd.read_csv(self.path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["        self.dsname = 'heart.csv'\n","        self.dtypes = ['Numeric', 'Categorical', 'Categorical', 'Numeric', 'Numeric',\n","                       'Categorical', 'Categorical', 'Numeric', 'Categorical', 'Numeric',\n","                       'Categorical', 'Categorical', 'Categorical', 'Categorical']\n","    def getHeading(self):\n","        return self.names\n","    def datasetDetails(self):\n","        return self.ds, self.dsname, self.names, self.dtypes\n","    def statDetails(self):\n","        print(self.ds.describe())\n","    \n","    def getDataset(self):\n","        return self.ds\n","    \n","    def getDatasetLess(self):\n","        return self.dsl, self.names\n","    def datasetOverview(self):\n","        return self.ds, self.dsname, self.names, self.dtypes\n","    def dataVizBoxplot(self):\n","        self.ds.plot(kind='box', subplots=True,\n","                     layout=(2, 2), sharex=False, sharey=False)\n","        pyplot.savefig('boxplot.png')\n","        pyplot.show()\n","    def dataVizHist(self):\n","        self.ds.hist()\n","        pyplot.savefig('boxplot.png')\n","        pyplot.show()\n","    def dataScatterMatrix(self):\n","        scatter_matrix(self.ds)\n","        pyplot.show()\n","\n","    # classification methods\n","    def classificationModels(self):\n","        from sklearn.model_selection import train_test_split\n","        from sklearn.metrics import accuracy_score\n","        from sklearn.linear_model import LogisticRegression\n","\n","        # split dataset into training and testing sets\n","        predictors = self.ds.drop(\"target\", axis=1)\n","        target = self.ds[\"target\"]\n","        X_train, X_test, Y_train, Y_test = \\\n","            train_test_split(predictors, target,\n","                             test_size=0.20, random_state=0)\n","        results = []\n","        methods = ['Logistic Regression', 'Support Vector Machine',\n","                   'K-Nearest Neighbourhood',\n","                   'Random Forest Classifier']\n","        lr = LogisticRegression()\n","        lr.fit(X_train, Y_train)\n","        Y_pred_lr = lr.predict(X_test)\n","        score_lr = round(accuracy_score(Y_pred_lr, Y_test)*100, 2)\n","        print(\"Logistic Regression: \",score_lr)\n","        results.append(score_lr)\n","\n","        # nb = GaussianNB()\n","        # nb.fit(X_train,Y_train)\n","        # Y_pred_nb = nb.predict(X_test)\n","        # score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)\n","        # print(score_nb)\n","        # results.append(score_nb)\n","        from sklearn import svm\n","        sv = svm.SVC(kernel='linear')\n","        sv.fit(X_train, Y_train)\n","        Y_pred_svm = sv.predict(X_test)\n","        score_svm = round(accuracy_score(Y_pred_svm, Y_test)*100, 2)\n","        print(\"Support Vector Machine: \",score_svm)\n","        results.append(score_svm)\n","        knn = KNeighborsClassifier(n_neighbors=7)\n","        knn.fit(X_train, Y_train)\n","        Y_pred_knn = knn.predict(X_test)\n","        score_knn = round(accuracy_score(Y_pred_knn, Y_test)*100, 2)\n","        print(\"K-Nearest Neighbour: \",score_knn)\n","        results.append(score_knn)\n","        \n","\n","        # dt = DecisionTreeClassifier()\n","        # dt.fit(X_train,Y_train)\n","        # Y_pred_dt=dt.predict(X_test)\n","        # score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)\n","        # print(score_dt)\n","        # results.append(score_dt)\n","        # print(results)\n","        rf = RandomForestClassifier()\n","        rf.fit(X_train, Y_train)\n","        Y_pred_rf = rf.predict(X_test)\n","        score_rf = round(accuracy_score(Y_pred_rf, Y_test)*100, 2)\n","        print(\"Random Forest: \",score_rf)\n","        results.append(score_rf)\n","        print(results)\n","        return results, methods\n","    def getPredictions(self):\n","        from sklearn.model_selection import train_test_split\n","        from sklearn.metrics import accuracy_score\n","        from sklearn.linear_model import LogisticRegression\n","\n","        # split dataset into training and testing sets\n","        predictors = self.ds.drop(\"target\", axis=1)\n","        target = self.ds[\"target\"]\n","        X_train, X_test, Y_train, Y_test = \\\n","            train_test_split(predictors, target,\n","                             test_size=0.20, random_state=0)\n","        results = []\n","        methods = ['Logistic Regression', 'Naive Bayes Classifier', 'Support Vector Machine',\n","                   'K Nearest Neighbourhood', 'DecisionTreeClassifier',\n","                   'Random Forest Classifier']\n","        lr = LogisticRegression()\n","        lr.fit(X_train, Y_train)\n","        Y_pred_lr = lr.predict(X_test)\n","        score_lr = round(accuracy_score(Y_pred_lr, Y_test) * 100, 2)\n","        print(\"Logistic Regression: \",score_lr)\n","        results.append(score_lr)\n","\n","        # nb = GaussianNB()\n","        # nb.fit(X_train, Y_train)\n","        # Y_pred_nb = nb.predict(X_test)\n","        # score_nb = round(accuracy_score(Y_pred_nb, Y_test) * 100, 2)\n","        # print(score_nb)\n","        # results.append(score_nb)\n","        from sklearn import svm\n","        sv = svm.SVC(kernel='linear')\n","        sv.fit(X_train, Y_train)\n","        Y_pred_svm = sv.predict(X_test)\n","        score_svm = round(accuracy_score(Y_pred_svm, Y_test) * 100, 2)\n","        print(\"SVM: \",score_svm)\n","        results.append(score_svm)\n","        knn = KNeighborsClassifier(n_neighbors=7)\n","        knn.fit(X_train, Y_train)\n","        Y_pred_knn = knn.predict(X_test)\n","        score_knn = round(accuracy_score(Y_pred_knn, Y_test) * 100, 2)\n","        print(score_knn)\n","        results.append(score_knn)\n","        print(results)\n","\n","        # dt = DecisionTreeClassifier()\n","        # dt.fit(X_train, Y_train)\n","        # Y_pred_dt = dt.predict(X_test)\n","        # score_dt = round(accuracy_score(Y_pred_dt, Y_test) * 100, 2)\n","        # print(score_dt)\n","        # results.append(score_dt)\n","        # print(results)\n","        rf = RandomForestClassifier()\n","        rf.fit(X_train, Y_train)\n","        Y_pred_rf = rf.predict(X_test)\n","        score_rf = round(accuracy_score(Y_pred_rf, Y_test) * 100, 2)\n","        print(score_rf)\n","        results.append(score_rf)\n","        print(results)\n","        print(Y_pred_rf)\n","        print(Y_test.head(5))\n","        print(Y_test.shape)\n","        return results, methods, Y_pred_rf, Y_test, self.names\n","    def getPredictionValue(self, input_data):\n","        import numpy as np\n","        predictors = self.ds.drop(\"target\", axis=1)\n","        target = self.ds[\"target\"]\n","        ################\n","        X_train, X_test, Y_train, Y_test = \\\n","            train_test_split(predictors, target,\n","                             test_size=0.20, random_state=0)\n","        print(X_test)\n","        rf = RandomForestClassifier()\n","        rf.fit(X_train, Y_train)\n","        # change the input data to a numpy array\n","        input_data_as_numpy_array = np.asarray(input_data)\n","\n","        # reshape the numpy array as we are predicting for only on instance\n","        input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n","        prediction = rf.predict(input_data_reshaped)\n","        print(prediction)\n","        if (prediction[0] == 0):\n","            print('The Person does not have a Heart Disease')\n","        else:\n","            print('The Person has Heart Disease')\n","\n","        ###############\n","        return prediction  # score_rf\n","    def classificationBoxPlot(self):\n","        pyplot.boxplot(self.results, labels=self.names)\n","        pyplot.title('Algorithm Comparison')\n","        pyplot.show()"]},{"cell_type":"markdown","metadata":{},"source":["data = (63,1,3,145,233,1,0,150,0,2.3,0,0,1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["obj = Classification()\n","# p = obj.getPredictionValue(data)\n","obj.classificationModels()\n","# print(p)\n","# print(s)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":2}
